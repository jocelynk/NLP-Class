{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from itertools import izip\n",
    "from sklearn.cross_validation import KFold\n",
    "import HTMLParser\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup Train/Test Tweebo files to extract features\n",
    "\n",
    "file_to_train = \"C:/Users/User/Documents/Cornell/Courses/NLP/HW4/test1.txt\"\n",
    "file_to_train_tweebo = \"C:/Users/User/Documents/Cornell/Courses/NLP/HW4/test2.txt\"\n",
    "result_file = \"C:/Users/User/Documents/Cornell/Courses/NLP/HW4/result.txt\"\n",
    "kaggle = False\n",
    "with open(file_to_train) as train:\n",
    "    input_lines = train.readlines()\n",
    "    labeled_tweets = []\n",
    "    arr = []\n",
    "    for line in input_lines:\n",
    "        try:\n",
    "            if line in ['\\n', '\\r\\n']:\n",
    "                labeled_tweets.append(arr)\n",
    "                arr = []\n",
    "            else:\n",
    "                if not kaggle:\n",
    "                    (word, tag) = line.split()\n",
    "                    arr.append((word, tag))\n",
    "                else:\n",
    "                    arr.append([line.strip()])\n",
    "                \n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "with open(file_to_train_tweebo) as train_tweebo:\n",
    "    input_lines = train_tweebo.readlines()\n",
    "    tweebo_tweets = []\n",
    "    arr = []\n",
    "    for line in input_lines:\n",
    "        try:\n",
    "            if line in ['\\n', '\\r\\n']:\n",
    "                tweebo_tweets.append(arr)\n",
    "                arr = []\n",
    "            else:\n",
    "                (word_id, word, lemma, cpostag, postag, feats, head, dep_relation) = line.split()\n",
    "                arr.append((word, word_id, postag, head, dep_relation));\n",
    "        except ValueError:\n",
    "            continue\n",
    "            \n",
    "features = []\n",
    "\n",
    "for s1, s2 in zip(labeled_tweets, tweebo_tweets):\n",
    "    tweebo_index = 0\n",
    "    sentence = []\n",
    "    head_diff = 0\n",
    "    head_point = 0\n",
    "    head_point_arr = []\n",
    "    head_diff_arr = []\n",
    "    raw_sentence = []\n",
    "    for i in range(len(s1)):\n",
    "        word1 = s1[i][0]\n",
    "        escaped_word1 = HTMLParser.HTMLParser().unescape(s1[i][0]) \n",
    "        word2 = HTMLParser.HTMLParser().unescape(s2[tweebo_index][0]) \n",
    "        t_ind = tweebo_index\n",
    "        raw_sentence.append(escaped_word1)\n",
    "        if(word1 != word2 and escaped_word1 != word2):\n",
    "            head_point = i+1\n",
    "            head_point_arr.append(head_point)\n",
    "            while True:\n",
    "                if(word2 == word1 or word2 == escaped_word1):\n",
    "                    break;\n",
    "                else:\n",
    "                    head_diff += 1\n",
    "#                     if(int(s2[tweebo_index][3]) == -1 and int(s2[t_ind][3]) == -1):\n",
    "#                         t_ind += 1\n",
    "                    if((int(s2[tweebo_index][3]) != -1 and t_ind != tweebo_index)):\n",
    "                        t_ind = tweebo_index\n",
    "                    tweebo_index += 1\n",
    "                    word2 += HTMLParser.HTMLParser().unescape(s2[tweebo_index][0])\n",
    "            head_diff_arr.append(head_diff)\n",
    "            \n",
    "        if not kaggle:\n",
    "            sentence.append([i+1, escaped_word1, s1[i][1], s2[t_ind][2], int(s2[t_ind][3]), s2[t_ind][4]])\n",
    "        else:\n",
    "            sentence.append([i+1, escaped_word1, s2[t_ind][2], int(s2[t_ind][3]), s2[t_ind][4]])\n",
    "        tweebo_index += 1\n",
    "    #head indexes reconciliation\n",
    "    if len(head_diff_arr) > 0:\n",
    "        for word in sentence:\n",
    "            if not kaggle:\n",
    "                old_head = word[4]\n",
    "            else:\n",
    "                old_head = word[3]\n",
    "            if(old_head == -1 or old_head == 0):\n",
    "                continue\n",
    "\n",
    "            start = old_head - (len(s2) - len(s1)) - 2\n",
    "            end = old_head + (len(s2) - len(s1))\n",
    "\n",
    "            if(start < 0):\n",
    "                start = 0\n",
    "            if(end > len(sentence)):\n",
    "                end = len(sentence)\n",
    "\n",
    "            old_word = s2[old_head-1][0]\n",
    "            next_word = ''\n",
    "            if(old_head < len(s2)):\n",
    "                next_word = s2[old_head][0]\n",
    "            else:\n",
    "                next_word = ''\n",
    "            old_word_next = old_word + next_word\n",
    "            \n",
    "            if(old_head > 0):\n",
    "                prev_word = s2[old_head-2][0]\n",
    "            else:\n",
    "                prev_word = ''\n",
    "                \n",
    "            prev_old_word = prev_word + old_word\n",
    "            \n",
    "            new_word = ''\n",
    "\n",
    "            for i in xrange(start, end):\n",
    "                if(HTMLParser.HTMLParser().unescape(old_word) == sentence[i][1] \\\n",
    "                   or HTMLParser.HTMLParser().unescape(old_word_next) in sentence[i][1]\\\n",
    "                  or HTMLParser.HTMLParser().unescape(prev_old_word) in sentence[i][1]):\n",
    "                    new_word = sentence[i]\n",
    "\n",
    "            if not kaggle:\n",
    "                word[4] = new_word[0]\n",
    "            else:\n",
    "                word[3] = new_word[0]\n",
    "    features.append(sentence)\n",
    "    \n",
    "open(result_file, 'w').close()\n",
    "with open (result_file, 'w') as f: \n",
    "    for tweet in features:\n",
    "        for word in tweet:\n",
    "            f.write(' '.join(str(x) for x in word).strip())\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
